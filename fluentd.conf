# Master configuration file for google-fluentd

# Include any configuration files in the config.d directory.
#
# An example "catch-all" configuration can be found at
# https://github.com/GoogleCloudPlatform/fluentd-catch-all-config
@include config.d/*.conf

<system>
  log_level warn
</system>

# syslog is supported only as textPayload = no filters!
<source>
  @type forward
  bind 0.0.0.0
</source>

# Do not collect fluentd's own logs to avoid infinite loops.
<match fluent.**>
  @type null
</match>

# Add a unique insertId to each log entry that doesn't already have it.
# This helps guarantee the order and prevent log duplication.
<filter **>
  @type add_insert_ids
</filter>

# Convert Docker format to Gcloud format so msg body is displayed
<filter **>
  @type record_transformer
  <record>
    message ${record["log"]}
  </record>
  remove_keys log
</filter>

<match **>
    @type copy
    <store>
        @type stdout
        <format>
          output_type single_value
          message_key message
          time_format "%iso8601"
        </format>
    </store>
    <store>
      @type google_cloud
  
      buffer_type file
      buffer_path /var/log/google-fluentd/buffers
      
      # Set the chunk limit conservatively to avoid exceeding the recommended
      # chunk size of 5MB per write request.
      buffer_chunk_limit 512KB
      
      # Flush logs every 5 seconds, even if the buffer is not full.
      flush_interval 5s
      
      # Enforce some limit on the number of retries.
      disable_retry_limit false
      
      # After 3 retries, a given chunk will be discarded.
      retry_limit 3
      
      # Wait 10 seconds before the first retry. The wait interval will be doubled on
      # each following retry (20s, 40s...) until it hits the retry limit.
      retry_wait 10
      
      # Never wait longer than 5 minutes between retries. If the wait interval
      # reaches this limit, the exponentiation stops.
      # Given the default config, this limit should never be reached, but if
      # retry_limit and retry_wait are customized, this limit might take effect.
      max_retry_wait 300
      
      # Use multiple threads for processing.
      num_threads 2
      detect_json false
      
      # Enable metadata agent lookups.
      enable_metadata_agent false
      
      # Use the gRPC transport.
      use_grpc true
      
      # If a request is a mix of valid log entries and invalid ones, ingest the
      # valid ones and drop the invalid ones instead of dropping everything.
      partial_success true
  </store>
</match>
